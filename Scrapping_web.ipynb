{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scrapping Web Portal Berita"
      ],
      "metadata": {
        "id": "swx_E3OF0Cg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut ini adalah scrapping web portal berita untuk topik Universitas Brawijaya Selama tahun 2023"
      ],
      "metadata": {
        "id": "jgRlPwJb0KnM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik0KkgCFzeeD"
      },
      "outputs": [],
      "source": [
        "import requests as req\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from datetime import datetime\n",
        "import csv\n",
        "hades = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scrapping web portal berita Detik"
      ],
      "metadata": {
        "id": "gwb4OP0r1Xil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_detik(hal):\n",
        "    global hades\n",
        "    a = 1\n",
        "    for page in range(4,hal):\n",
        "        url_detik = f'https://www.detik.com/tag/universitas-brawijaya/?sortby=time&page={page}'\n",
        "        ge = req.get(url_detik,hades).text\n",
        "        sop = bs(ge,'lxml')\n",
        "        li = sop.find('div',class_='list media_rows list-berita')\n",
        "        lin = li.find_all('article')\n",
        "        for x in lin:\n",
        "            link = x.find('a')['href']\n",
        "            date = x.find('a').find('span',class_='date').text.replace('WIB','').replace('detikNews','').split(',')[1]\n",
        "            headline = x.find('a').find('h2').text\n",
        "            ge_ = req.get(link,hades).text\n",
        "            sop_ = bs(ge_,'lxml')\n",
        "            content = sop_.find_all('div',class_='detail__body-text itp_bodycontent')\n",
        "            for x in content:\n",
        "                x = x.find_all('p')\n",
        "                y  = [y.text for y in x ]\n",
        "                content_ = ''.join(y).replace('\\n', '').replace('ADVERTISEMENT','').replace('SCROLL TO RESUME CONTENT','')\n",
        "                print(f'done[{a}] > {headline[0:10]}')\n",
        "                a += 1\n",
        "                with open('data_detikcom.csv','a')as file:\n",
        "                    wr = csv.writer(file, delimiter=',')\n",
        "                    wr.writerow([headline,date,link,content_])"
      ],
      "metadata": {
        "id": "7vHzmQPxzodJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_detik(22)"
      ],
      "metadata": {
        "id": "7H77K7_A1kJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c41435-7ef0-48e8-d4e3-343069250d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done[1] > Wapres Kun\n",
            "done[2] > Rektor UB \n",
            "done[3] > Permudah M\n",
            "done[4] > Pakar Poli\n",
            "done[5] > Eksekutif \n",
            "done[6] > Gubes UB D\n",
            "done[7] > Mengenal T\n",
            "done[8] > Gedung Fil\n",
            "done[9] > Muncul Sur\n",
            "done[10] > UB Ungkap \n",
            "done[11] > Beredar Wa\n",
            "done[12] > Fakta Baru\n",
            "done[13] > Infografis\n",
            "done[14] > Pilu Manta\n",
            "done[15] > 7 Fakta Pi\n",
            "done[16] > Tragis Man\n",
            "done[17] > Mantan Mah\n",
            "done[18] > Terkuak Ko\n",
            "done[19] > Ditemukan \n",
            "done[20] > Terungkap \n",
            "done[21] > UB Serahka\n",
            "done[22] > Suara Bend\n",
            "done[23] > UB Buka Su\n",
            "done[24] > Mahasiswi \n",
            "done[25] > Polisi Sel\n",
            "done[26] > Ada Suara \n",
            "done[27] > Mahasiswi \n",
            "done[28] > Mahasiswi \n",
            "done[29] > Suara Bend\n",
            "done[30] > Seorang Ma\n",
            "done[31] > Mitigasi K\n",
            "done[32] > Penyanyi D\n",
            "done[33] > Jokowi Did\n",
            "done[34] > Ini Eunoia\n",
            "done[35] > Ada Tata C\n",
            "done[36] > UB Datangi\n",
            "done[37] > Manfaatkan\n",
            "done[38] > Riset 5 Ma\n",
            "done[39] > UB Akan Ku\n",
            "done[40] > Alasan Pen\n",
            "done[41] > Pengelola \n",
            "done[42] > Pakai Ener\n",
            "done[43] > Mahasiswa \n",
            "done[44] > Kisah Haru\n",
            "done[45] > Mahasiswa \n",
            "done[46] > Kisah Mist\n",
            "done[47] > Tim PKM Un\n",
            "done[48] > Wedhus Ken\n",
            "done[49] > Sederet Te\n",
            "done[50] > Pengalaman\n",
            "done[51] > Mahasiswa \n",
            "done[52] > Kengerian \n",
            "done[53] > Kreatif! M\n",
            "done[54] > Cek Inform\n",
            "done[55] > Lulus dari\n",
            "done[56] > Contohlah \n",
            "done[57] > Lulus 3,5 \n",
            "done[58] > Mahasiswa \n",
            "done[59] > UB Dirikan\n",
            "done[60] > FIB UB Ken\n",
            "done[61] > UB Segera \n",
            "done[62] > Kisah Anni\n",
            "done[63] > 3 Kampus J\n",
            "done[64] > Ortu Sulta\n",
            "done[65] > Teganya 5 \n",
            "done[66] > Sebelum Te\n",
            "done[67] > 4 Orang Te\n",
            "done[68] > Polisi Dal\n",
            "done[69] > Mahasiswa \n",
            "done[70] > Innalillah\n",
            "done[71] > Pendakian \n",
            "done[72] > Fakta-fakt\n",
            "done[73] > Pendaki Te\n",
            "done[74] > Upaya Medi\n",
            "done[75] > Aliansi Ci\n",
            "done[76] > Viral Maba\n",
            "done[77] > 5 Fakta Pu\n",
            "done[78] > Heboh Pulu\n",
            "done[79] > 4 Fakta Vi\n",
            "done[80] > UB Buka Su\n",
            "done[81] > Viral Maha\n",
            "done[82] > Fadel Muha\n",
            "done[83] > Sosok Koca\n",
            "done[84] > Aksi Kocak\n",
            "done[85] > 10 Kampus \n",
            "done[86] > Heboh Ratu\n",
            "done[87] > Penjelasan\n",
            "done[88] > Viral Ratu\n",
            "done[89] > Kisah Maba\n",
            "done[90] > Pendaftara\n",
            "done[91] > Cerita Cam\n",
            "done[92] > Mahasiswa \n",
            "done[93] > Sosok Azza\n",
            "done[94] > Dua Mahasi\n",
            "done[95] > Perkenalka\n",
            "done[96] > Fakta-fakt\n",
            "done[97] > Peneliti U\n",
            "done[98] > Seleksi Ma\n",
            "done[99] > Universita\n",
            "done[100] > Prodi Psik\n",
            "done[101] > Cara Dafta\n",
            "done[102] > Seleksi Ma\n",
            "done[103] > Syarat Daf\n",
            "done[104] > 8 Kos Seki\n",
            "done[105] > Universita\n",
            "done[106] > EM UB Sebu\n",
            "done[107] > Jadwal Sel\n",
            "done[108] > EM UB Demo\n",
            "done[109] > Bosan Jadi\n",
            "done[110] > UB Buka Ja\n",
            "done[111] > UB Buka Ja\n",
            "done[112] > Tantangan \n",
            "done[113] > 5.734 Calo\n",
            "done[114] > Bela EM UB\n",
            "done[115] > EM UB Tant\n",
            "done[116] > Wakil Rekt\n",
            "done[117] > Bantahan W\n",
            "done[118] > Kampus UB \n",
            "done[119] > Ketika EM \n",
            "done[120] > Program Di\n",
            "done[121] > Program EM\n",
            "done[122] > Program EM\n",
            "done[123] > Ngalam Mbo\n",
            "done[124] > Siap-siap \n",
            "done[125] > Jalur Mand\n",
            "done[126] > Wamenkumha\n",
            "done[127] > Mapala UB \n",
            "done[128] > Simak Besa\n",
            "done[129] > 8 Spot Kul\n",
            "done[130] > 25 Tempat \n",
            "done[131] > 14 Jurusan\n",
            "done[132] > Kepala OJK\n",
            "done[133] > 20 Jurusan\n",
            "done[134] > Seleksi Ma\n",
            "done[135] > 210 Pesert\n",
            "done[136] > 21.960 Pes\n",
            "done[137] > UB Siap Ge\n",
            "done[138] > Siap-siap \n",
            "done[139] > BNI & Alum\n",
            "done[140] > Cerita Dam\n",
            "done[141] > UB Gelar D\n",
            "done[142] > Pakar Nila\n",
            "done[143] > 20 Prodi P\n",
            "done[144] > Diterima S\n",
            "done[145] > Fakultas K\n",
            "done[146] > Universita\n",
            "done[147] > 20 PTN den\n",
            "done[148] > 20 PTN Pen\n",
            "done[149] > Pegadaian \n",
            "done[150] > Pendaftar \n",
            "done[151] > Terbaru! I\n",
            "done[152] > 10 Jurusan\n",
            "done[153] > Terima Hon\n",
            "done[154] > Erick Thoh\n",
            "done[155] > Daftar Pro\n",
            "done[156] > Ini Daya T\n",
            "done[157] > Terseret K\n",
            "done[158] > Sinyal Pra\n",
            "done[159] > Terkuak Ma\n",
            "done[160] > 7 Orang Di\n",
            "done[161] > Keracunan \n",
            "done[162] > Pengakuan \n",
            "done[163] > UB Klaim M\n",
            "done[164] > Bukan 510,\n",
            "done[165] > Makan Mala\n",
            "done[166] > Ratusan Ma\n",
            "done[167] > Ratusan Ma\n",
            "done[168] > Detik-deti\n",
            "done[169] > Versi Poli\n",
            "done[170] > 510 Mahasi\n",
            "done[171] > Simak Kuot\n",
            "done[172] > Best Pract\n",
            "done[173] > Infografis\n",
            "done[174] > Daftar Jur\n",
            "done[175] > Universita\n",
            "done[176] > Cerita Sho\n",
            "done[177] > Alat Detek\n",
            "done[178] > Orang Tua \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scrapping web portal berita Kompas"
      ],
      "metadata": {
        "id": "diaTp7HP1gRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_kompas(hal):\n",
        "    global hades\n",
        "    a = 1\n",
        "    for page in range(2,hal):\n",
        "      url_kompas = f'https://www.kompas.com/tag/universitas+brawijaya/?sortby=time&page={page}'\n",
        "      ge = req.get(url_kompas,hades).text\n",
        "      sop = bs(ge,'lxml')\n",
        "      li = sop.find('div',class_='latest ga--latest mt2 clearfix -newlayout')\n",
        "      lin = li.find_all('div', class_='article__list clearfix')\n",
        "      for x in lin:\n",
        "        divdate = x.find('div', class_='article__list__info')\n",
        "        # data tanggal\n",
        "        date = divdate.find('div', class_='article__date').text\n",
        "        # data judul\n",
        "        divtitle = x.find('div', class_='article__list__title')\n",
        "        title = divtitle.find('h3')\n",
        "        titletext = title.find('a').text\n",
        "        # link berita\n",
        "        link = title.find('a')['href']\n",
        "        ge_ = req.get(link,hades).text\n",
        "        sop_ = bs(ge_,'lxml')\n",
        "        readcontent = sop_.find_all('div',class_='read__content')\n",
        "        a+=1\n",
        "        for x in readcontent:\n",
        "          x = x.find_all('p')\n",
        "          y  = [y.text for y in x ]\n",
        "          content_ = ''.join(y).replace('\\n', '').replace('ADVERTISEMENT','').replace('SCROLL TO RESUME CONTENT','').replace('KOMPAS.com - ', '').replace('MALANG, KOMPAS.com-', '')\n",
        "          print(f'done[{a}] > {titletext[0:10]}')\n",
        "          with open('data_kompascom.csv','a')as file:\n",
        "            wr = csv.writer(file, delimiter=',')\n",
        "            wr.writerow([titletext,date,link,content_])"
      ],
      "metadata": {
        "id": "n0ThwmF7O9Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_kompas (8)"
      ],
      "metadata": {
        "id": "EKrdwNObaCVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scrapping web portal berita MedCom"
      ],
      "metadata": {
        "id": "itwFuPI-1joE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_medcom(hal):\n",
        "    global hades\n",
        "    a=0\n",
        "    for page in range (0, hal):\n",
        "      url_medcom = f'https://www.medcom.id/tag/15343/universitas-brawijaya/{30*page}'\n",
        "      ge = req.get(url_medcom, hades).text\n",
        "      sop = bs(ge,'lxml')\n",
        "      li = sop.find('ul',class_='box_21_ct one')\n",
        "      lin = li.find_all('li')\n",
        "      for x in lin:\n",
        "        div_x = x.find('div', class_='text')\n",
        "        divdate = div_x.find ('div', class_='foot_article')\n",
        "        # data tanggal\n",
        "        date = divdate.find('span', class_='pl0').text.replace('class=\"fa fa-clock\"></i>', '')\n",
        "        #data judul\n",
        "        divtitle = div_x.find('h4')\n",
        "        title = divtitle.find('a').text\n",
        "        #link berita\n",
        "        link = divtitle.find ('a')['href']\n",
        "        ge_ = req.get(link, hades).text\n",
        "        sop_ = bs(ge_,'lxml')\n",
        "        divreadcontent = sop_.find('div',class_='article_ct')\n",
        "        readcontent = divreadcontent.find_all('div', class_='text')\n",
        "        a+=1\n",
        "        for x in readcontent:\n",
        "          content_ = x.get_text(separator=' ', strip=True)\n",
        "          content_ = content_.replace('ADVERTISEMENT','').replace('SCROLL TO RESUME CONTENT','').replace('Jangan lupa ikuti update berita lainnya dan follow akun google news Medcom.id', '')\n",
        "          print(f'done[{a}] > {title[0:10]}')\n",
        "          with open('data_medom.csv','a')as file:\n",
        "            wr = csv.writer(file, delimiter=',')\n",
        "            wr.writerow([title,date,link,content_])"
      ],
      "metadata": {
        "id": "hBt-pLeeCRa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_medcom (4)"
      ],
      "metadata": {
        "id": "PRUvespoHBTR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}